\section{LGLN:  Towards Interpretability and Performance}\label{sec:dgn-no-act}
In this section, we turn to the issues of entanglement and `black box'-ness. Continuing with the `learning in gates + learning in the weights given gates' interpretation, using LGLN (\Cref{fig:lgln}), we disentangle both `learning in the gates' as well as `learning in the weights given gates'. The aim of such disentangling is to show that the commonly held view of sophisticated structures are learnt in a layer-by-layer manner is misconceived. We now elaborate on how the disentangling is achieved.

$\bullet$ \textbf{Disentangling Learning in Gates.}  The gates themselves encode binary information and are triggered by their pre-activations. While it was shown that \citep{npk} the gates play a key role, the transformation from the input to the pre-activation to the gates happens through the hidden layers, in which the linear and non-linear operations are entangled. The hidden layers are not interpretable, and we have to fall back to sophisticated structures being learnt in the hidden layers as an explanation for why it is possible to learn useful pre-activations (as hence useful gates). In LGLN, the non-linear ReLU is removed, and the transformation in linear, i.e., while the learning of pre-activations happens in a layer-by-layer manner, the learnt structures are no longer sophisticated and are interpretable in terms of standard linear algebra. Note that the LGLN is same as a DGN in which the ReLUs in the feature network are replaced by identity activations.


$\bullet$ \textbf{Disentangling Learning in Weights Given Gates.} Interpreted in a layer-by-layer manner, the GaLUs and linear operations are entangled. However, once the gates are given, we claim that we can switch over to path-by-path view and we need not look at the what happens layer-by-layer. The reason for providing a constant $\mathbf{1}$ input (in the bottom network of the LGLN) is to drive home the fact that the input is required only generate the gates, which in turn dictate which paths are active and which are inactive. In other words, the neural path value is a vector specifying the contribution of each path to the final output and (since signal at input node is $1$) the neural path feature is a vector specifying the path activity, i.e., which path to be selected and which one to be left out in the output.

The linearity of the pre-activations is ensured via construction itself and needs no further theoretical justification, and in what follows, we experimentally verify that linearly learnt pre-activations does not degrade performance significantly. The claim that learning of the weights given the gates is disentangled in the path space are also justified theoretically and experimentally. 



%Given a DNN, there are two corresponding networks, the LGLN  in \Cref{sec:intro} and the DGN in \Cref{sec:prelim}. The LGLN can be obtained from the DGN by,

%(i) replacing all the ReLU activations in the feature network 

%The DGN performs only marginally poor compared to the DNN, and by successfully addressing the `black box'-ness issue in a DGN we will have both performance and interpretability. We now propose our novel \texttt{DGN-NO-ACT}  which disentangles the computations into (i) primal linear layer-by-layer computation, (ii) dual linear path-by-path computation and (iii) gating non-linearity which \emph{lifts} the computations from the primal to the dual. \texttt{DGN-NO-ACT} (right diagram in \Cref{fig:dgn}) is obtained by making a novel modification to the DGN (left diagram in \Cref{fig:dgn}) as follows:

%1. We replace the ReLUs in the feature network with \emph{identity} maps, i.e., $I(q) = q$. Thus, in the \texttt{DGN-NO-ACT}, the transformation from input to the pre-activations is entirely linear. We call this \textbf{primal linearity}. The disentanglement happens because the ReLU  is completely removed.  

%2. The value network of the DGN is linear in dual `path' variables. We call this \textbf{dual linearity} which stands for the fact that the value network computes path-by-path, and not layer-by-layer. As a result, presenting a $\mathbf{1}$ as input to the value network in \texttt{DGN-NO-ACT} does not degrade performance. The simplifications are : (i) $v_{\Tv}\in \R^{\text{total\,paths}}$ is a vector that does not depend on the input, and (ii) $\phi_{\Tf}(x)\in(0,1)^{\text{total\,paths}}$ is a  simple feature vector. In other words, the value network  learns the paths, and the feature network learns the activations of paths for each input.  While in each layer of the value network GaLUs and the linear operations are entangled, disentanglement happens in the path variables, and we do not have to worry about how learning happens layer-by-layer.

%3. The gates themselves serve the functionality of \emph{lifting} the computations from the primal to the dual, i.e., pre-activations trigger the gates which in turn activate the paths.

%\textbf{Significance.} The salient importance of the \texttt{DGN-NO-ACT} is that it clearly separates the layer-by-layer computations in the feature network and path-by-path computation in the value network. The importance of primal linearity is that we can now use standard linear algebra to `mathematically' interpret the linear transformations from the input to the pre-activations. Also, in the case of specific application domains such as `image classification', these transformations are `filter banks' which have been extensively studied with well known interpretations. The `mathematical' as well as domain specific interpretabilities obviate the need for `locally linear explanation using simpler models': the feature network is entirely linear and is itself simple. The importance of dual linearity is that it gives us a \emph{kernel} based `mathematical' interpretation in the \emph{infinite width regime}. 


%\textbf{DGN-NO-ACT(our model)}(see right diagram in \Cref{fig:dgn}). We replace the ReLUs in the feature network with \emph{identity} maps, i.e., $I(q) = q$. Thus, in the \texttt{DGN-NO-ACT}, the transformation from input to the pre-activations is entirely linear and is amenable to interpertation via standard spectral analysis using linear algebraic tools. The pre-activations trigger the gates, which then dictates the path activity. The value network is given only given $\mathbf{1}$ as input and hence $v_{\Tv}\in \R^{\text{total\,paths}}$ is a vector that does not depend on the input, and $\phi_{\Tf}(x)\in(0,1)^{\text{total\,paths}}$ is a very simple feature vector. % and the output $\hat{y}_{\text{DGN}}(x)=\ip{\phi_{\Tf}(x),v_{\Tv}}=\sum_{p}\phi_\Tf(x,p)v_\Tv(p)$ is equal to \emph{\textbf{the summation of `path value' weighted by the `path activations'}}. 
%Thus, the \texttt{DGN-NO-ACT} can be seen to disentangle the `primal linear' feature network which generates the gates, which in turn activate the paths in the value network which is the `dual linear'.

%\textbf{Remark.} Presenting the value network with $\mathbf{1}$ is very counter intutive, which will get justfied in theory as well as experiments in the next section. As a quick check, we the test accuracies of a DNN $4$ with convolutional layers and global-average-pooling (GAP), its corresponding DGN and \texttt{DGN-NO-ACT} on CIFAR-10 are {\bf{DNN: $80.4\%$,  DGN: $77.4\%$, \texttt{DGN-NO-ACT} : $74.5\%$}}.

%Since $\hat{y}_{\Theta}(x)=\ip{\phi_{x,\Theta},v_{\Theta}}$, during training, as $\Theta$ is learnt, both the NPFs and NPV are also learnt. To understand their roles better, $\phi_{x,\Theta}$ and $v_{\Theta}$ have to be separated.  This is achieved by the deep gated network (DGN) setup (see \Cref{fig:dgn}), which has two networks of \emph{identical architecture} namely the \emph{feature network} ($\Tf\in\R^{d^{\text{f}}_{\text{net}}}$) which holds the NPFs (i.e., the gating information) and the \emph{value network} ($\Tv\in\R^{d^{\text{v}}_{\text{net}}}$) which holds the NPV.  The combined parameterisation is denoted by $\Theta^{\text{DGN}}=(\Tf,\Tv)\in \R^{d^{\text{f}}_{\text{net}}+d^{\text{v}}_{\text{net}}}$.  The feature network is a DNN with ReLUs and the value network is a DNN with \emph{Gated Linear Units (GaLUs)} (terminology used in [\citenum{sss}]) whose output is the product of its pre-activation input $q^{\text{v}}(x)$and the external gating signal $G^{\text{f}}(x)$ (see \Cref{fig:dgn}). In \Cref{fig:dgn}, the main output of the DGN is $\hat{y}_{\text{DGN}}(x)$, while the other output $\hat{y}_{\text{f}}(x)$ is used to \emph{pre-train} the gates (see \Cref{sec:exp}).

