\section{Introduction}
Despite their success deep neural networks (DNNs) are still largely considered as black boxes. The larger aim of this paper is to argue that, at least in the case of DNNs with rectified linear units (ReLUs), the issue of `black box'-ness can be addresses successfully by simple a change of perspective/viewpoint.  To elaborate, the issue has less to do with the models themselves. Instead the issue is mostly a conceptual one arising from the primal view which is partial and incomplete. The primal view is that, as computation in a DNN proceeds from the input to the output, in a layer-by-layer manner, increasingly sophisticated features are learnt in the hidden layers of the DNN, and the final layer learns a linear model with the hidden features output by the penultimate layer. The conceptual issue with the primal view is that, only the final layer is linear and amenable to a feature/weight interpretation, and even then, the hidden features i.e., the penultimate layer outputs, obtained as a result of several non-linear operations on the input are not interpretable themselves in a straightforward and intuitive manner. Recently \cite{npk} used the \emph{dual view} to investigate the role of gates (i.e., \emph{on/off} state) of the ReLUs. In this paper, we argue that the dual view complements the primal view, and both views considered together in the right order and proportion, helps us to resolve the `black box'-ness issue successfully, and culminating in an entirely interpretable white box model.

We first briefly describe the dual view. In the dual view, computations are projected onto the space of paths, wherein, each path starts from the input node, passes through a weight and a ReLU in each layer and ends at an output node. A path is `active' (i.e., `on') if all the gates in the path are `active' (i.e. `on). Now, each active path has a signal at its input node, which it transmits to the output. If the path is active, on its way to the output, the input signal of a path is scaled by a `value' which is equal the product of the weights in the path. If we are to draw an analogy to the standard feature weight decomposition, the product of signal at the input node and the path activity is conceptually akin to feature, and the `value' (which here is a product of the weights in the path) is conceputally akin to weight: the feature as well as the `value' here reside in $\R^{\text{total.no.paths}}$.


We now discuss how to mix and match the primal and the dual views, what are the natural questions that arise in this context. The gating pattern (which we call gating features for now) dictates the path activity, and is obtained in a layer-by-layer fashion; this is the only place where we need the primal view. Once we have the gating features, we can switch over to the dual view, because, we now know the path activations entirely, and the weights are to be seen as producing the scaling `values' for each path. This brings us to the following natural questions, some of which was answered in the prior work by \cite{npk} (which we review in \Cref{sec:prelim}), and some of which will be answered in this paper.

\emph{Q1: The gating features as well the `values' are produced by the weights. How to separate the two?}

A1: This is achieved by a deep gated network (DGN) which has two networks, one to produce the gates and the other to carry out input to output computation using the gates as external masks.
%a \emph{feature network} to produce the gating features and a value network which uses the gates are external masks to the weights. %\todoch{elaborate; say ReLU and GaLU}

\emph{Q2: Are gating features actually features? or How much information is there in these?}

A2: %In a linear model, all input dependent information is in the feature and once we have the features, we can train the weights. 
Gating features indeed perform a similar functional role akin to the features in a linear model. Using the gates of pre-trained DNN as external masks and training the weights recovers the performance of the pre-trained DNN. So, almost all information is in the gating features.

\emph{Q3: Are gating features being learnt during training?}

A3: Yes, the gating features obtained from a pre-trained DNN performs much better than gating features obtained from a randomly initialised DNN. It was shown that the learning in the gating features is the difference between finite and infinite width DNNs.

\emph{Q4: Can we learn gating features?}

A4: Yes. By training the feature and value network together, we can learn the weights and gates separately, without significant drop in performance.

\emph{Q5: Do we have an analytical characterisation of gating features?}

A5: The gating features are formally characterised by the so called \emph{neural path kernel} (NPK) which is equal to the \emph{Hadamard} product of the input Gram matrix and a correlation matrix which measures the overlap between the sub-networks of paths active for the various input pairs.

%The dual view decomposes the computation in a DNN into two parts (i) computation in the gates which is input dependent and (ii) computation in the weights which is the same across inputs. Based on this decomposition, the gates are separated from the weights. The information in the gates is then characterised by keeping the gates fixed, applying them as external masks and then training the weights. In this setting, the following interesting results were shown:

%1. \textbf{ Most information is in the gates}. Using the gates from a pre-trained DNN as external masks one can retrain the weights and match the test accuracy of the original pre-trained DNN with ReLU. 

%2. \textbf{Gate Are Learnt.} It was shown that gates are learnt during training and it improves test accuracy. It was shown that if gates from a randomly initialised (instead of pre-trained) DNN are used as external masks, and the weights are trained, the test accuracy drops significantly. This implies that gates are learnt when a DNN with ReLU is trained.
  
%This implies that most useful input dependent information is in the gates. 

%3. \textbf{Neural Path Kernel For Subnetwork.} For any given input, computation from input to output happens via the `active subnetwork' consisting of active paths.
%It was show that the information stored in the gates is analytically characterised by \emph{neural path kernel} (NPK) which is equal to the \emph{Hadamard} product of the input Gram matrix and a correlation matrix which measures the overlap between the sub-networks active for the input pairs.

%\subsection{Contribution and Organisation}
\emph{Q6: What more structure is there to the gating features? Do architectures such as convolution with pooling and skip connection add more structure?}

\textbf{Contribution I:} In \Cref{sec:theory}, we refine the result of \cite{npk} for fully connected case, and extend the dual view to cover convolutions with global pooling and skip connections. Firstly, we notice that the NPK in prior work (see Q5 and A5) it is invariant to layer permutations. This permutation invariance was unnoticed in prior work, and is a key property of the gating features that has surprising and counter intuitive implications (see Q7 and A7 below). In \Cref{th:fc}, we essentially rewrite the prior NPK expression in a way that explicitly reveals this permutation invariance. The main highlight is that each layer is associated with a base kernel which measures the average correlation of gates, and the NPK is a \emph{Hadamard} product of the input Gram matrix and the base kernels. Here, the role of width is averaging and the role of depth is endowing the product structure from which the permutation invaraince ensues. In \Cref{th:conv} we show that the role of convolutions with global pooling is to provide rotational invariance to the NPK. In \Cref{th:res} we show that the role of skip connections is to provide an ensemble structure to NPK. 

\emph{Q7: How indispensable is the dual view for understanding the inner workings of DNNs? }

\textbf{Contribution II:} Once we have the gates, we show that destroying the layer by layer structure by permuting the gates does not cause performance to degrade at all. It could be argued that the network still manages to recover in a layer by layer manner despite such layer permutations. In order to eliminate this argument, we shut off input by using a constant $\mathbf{1}$ input, i.e., each path starts with $1$ at its input nodes, only the path activity is input dependent (since it is directly controlled by the gates). Using a constant $\mathbf{1}$ input does not degrade the performance either. From the primal viewpoint, these are surprising and counter intuitive results, however, in the dual view these are readily reconciled. In short, dual view is the right way to interpret the computations in the weights.
  
\emph{Q8: What happens when we train with random labels? }

\textbf{Contribution III:} In \Cref{sec:randlabel}, we show that upstream training with random labels followed by downstream training with true labels degrades the test performance because the upstream random labels degrade the gating features. The degradation in  the test performance in this setting was a question left open by \cite{randlabel}.

\emph{Q9: How to interpret the gating features which are obtained in a layer by layer manner involving non-linear activations? or Since the gating features have non-linear activations do we not have the `black box'-ness issue left unaddressed?}

\textbf{Contribution IV:} Having established that indespensiblity of the dual view, we turn to the gating features themselves. We answer Q9 by proposing a white box model in which information flows is as follows: (i) pre-activations are generated without non-linear activation, (ii) gating features are obtained from pre-activations, (iii) gates are applied as external masks and dictate the path activity (iv) all paths start with $1$ at their input node, i.e., the only way input affects the network is via the gates. We call this white box model \texttt{DGN-NO-ACT}, and we show that \texttt{DGN-NO-ACT}s based on VGG and a ResNet model achieve greater than $90\%$ and close to $70\%$ accuracy on CIFAR-10 and CIFAR-100 respectively. 


%Using the dual view, we interpret the roles of (i) width, (ii) depth, (iii) convolutions with global pooling and (iv) skip connections. For this, we refine and extend prior work to derive new results on the structure of NPK. We then present two new empirical results that are easily reconciled in the dual view (as opposed to the primal). These results are not meant to be techniques/tricks to improve performance that `beats state of the art'. The significance is that they showcase the power of dual view in resolving novel and unseen scenarios. We now list these contributions section-wise.

%$\bullet$ In \Cref{sec:theory}, we refine prior result on NPK (which depended on the correlation subnetworks) to show that NPK depends on the \emph{correlation of gates}. The main highlight is that each layer is associated with a base kernel which measures the average correlation of gates, and the NPK is a \emph{Hadamard} product of the input Gram matrix and the base kernels. This implies that the role of width is averaging and the role of depth is to form a product kernel. In \Cref{th:conv} we show that the role of convolutions with global pooling is to provide rotational invariance to the NPK. In \Cref{th:res} we show that the role of skip connections is to provide an ensemble structure to NPK.


%$\bullet$ In \Cref{sec:permute}, we present surprising results that are counter intuitive with respect to the primal view that progressively sophisticated structures are being in a layer by layer manner. Firstly, we show that destroying the layer by layer structure by permuting the gates does not cause performance to degrade at all. Secondly, we show that once the gates are obtained from the input, the network can be provided with a constant $\mathbf{1}$ input without degrading performance. We argue that these counter intuitive results are easily reconciled in the dual view.

%\emph{Part II: Open question related to training with random labels.}

% In \Cref{sec:randlabel}, we show that upstream training with random labels followed by downstream training with true labels degrades test accuracy because the random labels affects the gates. This degradation of test accuracy was an open question in \cite{randlabel}.


%\emph{Part III: Entirely interpretable and white box model.}

%In \Cref{sec:whitebox}, we propose a novel model by modifying  DNNs with ReLUs: we generate the pre-activation to the gates without any non-linear activations. Interpreted in the dual view, this novel model is entirely white box. We show white box models obtained by modifying VGG and a ResNet (in the proposed way) achieve greater than $90\%$ and close to $70\%$ on CIFAR-10 and CIFAR-100 respectively. 


%we propose a novel architecutre obtained by modifying DNNs with ReLUs, which, is conceptually same as DNNs with ReLUs but is entirely interpretable and white box. We effect the modification on a stardard model namely VGG and a ResNet model, to derive the corresponding white box models. We show these white box models achieve greater than $90\%$ and close to $70\%$ on CIFAR-10 and CIFAR-100 respectively. Here, the aim is to demonstrate that the new white box models improve interpretablity without significant loss in performance with respect to `state of the art'.


%We follow up this claim by completely removing the `black box'-n ess: we propose a novel architecutre, which, is conceptually same as DNNs with ReLUs but is entirely interpretable and white box. 
\begin{comment}
\subsection{Dual View}
In the dual view, the computation in a DNN is broken down into paths, wherein, each path starts from the input node, passes through a weight and a ReLU in each layer and ends at the output node. This gives a subnetwork intepretation: for any given input, computation from input to output happens via the `active subnetwork' consisting of active paths. This active subnetwork is in turn formed by the active gates in each layer. Each gate is a just a  simple `perceptron' which is described by the hyperplane of its incoming weights. As the the input passes through the layers, gates are turned on/off based on the angle between the layer input and the hyperplanes associated with the various gates in that layer. 


 The separation is achieved by a \emph{deep gated network} (DGN) setup, wherein, the input dependent gates are generated in a so called \emph{feature network} (which a DNN with ReLU whose sole  is  generation of the gates) and then gating signals are applied as external masks to a so called \emph{value network} which carries out the input to output computation. Having separated the gates and the weights, the role of gates and active subnetworks was investigated in theory and experiments.

%The main result  It was shown that most useful information is in the gates.  

%The dual view (i) gives simpler feature/value decomposition, (ii) gives a subnetwork intepretation and (iii) allows to separate the gates from the weights. We briefly described these below.

%Each path has a signal at its input node, which is gets transmitted to the output if the path is on (i.e., all the gates in the paths are on). On its way to the output, (if path is active) the input signal of a path is scaled by a `value' equal the product of the weights in the path. The input and the on/off of the path is encoded in a so called  and the scaling by the weights is encoded by the \emph{neural path value} (NPV $\in \R^{\text{total-paths}}$). This conceptual separation of computation in the gates encoded in the NPF and the computation in the weights in the NPV has the following favourable points:

%$\bullet$ \textbf{Simplicity.} The input and the gates of a path are  encoded in a \emph{neural path feature} (NPF $\in \R^{\text{total-paths}}$). The weights are encoded in a \emph{neural path value} (NPV $\in \R^{\text{total-paths}}$). The NPF coordinate of a path is $0$ if the path is inactive and is equal to the signal at the input node if the path is active.  The NPV coordinate of a path is the product of the weights in the path. The NPV of a path the scales signal at it input node, and the final DNN output is the inner product of NPF and NPV.

%$\bullet$ \textbf{Interpretability.} For any given input, computation from input to output happens via the `active subnetwork' consisting of active paths. This active subnetwork is in turn formed by the active gates in each layer. Each gate is a `perceptron' which is described by the hyperplane of its incoming weights. As the the input passes through the layers, gates are turned on/off based on the angle between the layer input and the hyperplanes associated with the various gates in that layer. 

%$\bullet$ \textbf{Separation.} 
%In a DNN with ReLUs, the weights play a dual role: (i) they decide the on/off activity of the gates, i.e., the NPF and they also dictate the NPV. 
%To understand the role of gates and weights separately, the gates are also physically separated from the weights in \emph{deep gated network} (DGN) setup, wherein, the input dependent gates are generated in a so called \emph{feature network} (which a DNN with ReLU whose sole  is  generation of the gates) and then gating signals are applied as external masks to a so called \emph{value network} which carries out the input to output computation. Having separated the gates and the weights, the role of gates and active subnetworks was investigated in theory and experiments.

1. \textbf{Gate Learning.} Most information is stored in the gates. Using the gates from a pre-trained DNN as external masks one can retrain the weights of the value network and match the test accuracy of the original pre-trained DNN with ReLU. It was shown that gates are learnt during training and it improves test accuracy.  
%This implies that most useful input dependent information is in the gates. 
%It was shown that if gates from a randomly initialised (instead of pre-trained) DNN are used as external masks, and the weights are trained, the test accuracy drops significantly. 
%This implies that gates are learnt when a DNN with ReLU is trained and

2. \textbf{Neural Path Kernel.} The information stored in the gates is analytically characterised by \emph{neural path kernel} (NPK) which is equal to the \emph{Hadamard} 
\end{comment}
\begin{comment}

\subsection{Dual View}
In the dual view, the computation in a DNN is broken down into paths, wherein, each path starts from the input node, passes through a weight and a ReLU in each layer and ends at the output node. This gives a subnetwork intepretation

 and allows to separate information in the gates from the weights. The main result  It was shown that most useful information is in the gates.  

%The dual view (i) gives simpler feature/value decomposition, (ii) gives a subnetwork intepretation and (iii) allows to separate the gates from the weights. We briefly described these below.

%Each path has a signal at its input node, which is gets transmitted to the output if the path is on (i.e., all the gates in the paths are on). On its way to the output, (if path is active) the input signal of a path is scaled by a `value' equal the product of the weights in the path. The input and the on/off of the path is encoded in a so called  and the scaling by the weights is encoded by the \emph{neural path value} (NPV $\in \R^{\text{total-paths}}$). This conceptual separation of computation in the gates encoded in the NPF and the computation in the weights in the NPV has the following favourable points:

%$\bullet$ \textbf{Simplicity.} The input and the gates of a path are  encoded in a \emph{neural path feature} (NPF $\in \R^{\text{total-paths}}$). The weights are encoded in a \emph{neural path value} (NPV $\in \R^{\text{total-paths}}$). The NPF coordinate of a path is $0$ if the path is inactive and is equal to the signal at the input node if the path is active.  The NPV coordinate of a path is the product of the weights in the path. The NPV of a path the scales signal at it input node, and the final DNN output is the inner product of NPF and NPV.

$\bullet$ \textbf{Interpretability.} For any given input, computation from input to output happens via the `active subnetwork' consisting of active paths. This active subnetwork is in turn formed by the active gates in each layer. Each gate is a `perceptron' which is described by the hyperplane of its incoming weights. As the the input passes through the layers, gates are turned on/off based on the angle between the layer input and the hyperplanes associated with the various gates in that layer. 

$\bullet$ \textbf{Separation.} 
%In a DNN with ReLUs, the weights play a dual role: (i) they decide the on/off activity of the gates, i.e., the NPF and they also dictate the NPV. 
To understand the role of gates and weights separately, the gates are also physically separated from the weights in \emph{deep gated network} (DGN) setup, wherein, the input dependent gates are generated in a so called \emph{feature network} (which a DNN with ReLU whose sole  is  generation of the gates) and then gating signals are applied as external masks to a so called \emph{value network} which carries out the input to output computation. Having separated the gates and the weights, the role of gates and active subnetworks was investigated in theory and experiments.

\textbf{Key Results.}  

1. \textbf{Gate Learning.} Most information is stored in the gates. Using the gates from a pre-trained DNN as external masks one can retrain the weights of the value network and match the test accuracy of the original pre-trained DNN with ReLU. It was shown that gates are learnt during training and it improves test accuracy.  
%This implies that most useful input dependent information is in the gates. 
%It was shown that if gates from a randomly initialised (instead of pre-trained) DNN are used as external masks, and the weights are trained, the test accuracy drops significantly. 
%This implies that gates are learnt when a DNN with ReLU is trained and

2. \textbf{Neural Path Kernel.} The information stored in the gates is analytically characterised by \emph{neural path kernel} (NPK) which is equal to the \emph{Hadamard} product of the input Gram matrix and a correlation matrix which measures the overlap between the sub-networks active for the input pairs.
\end{comment}
\begin{comment}

\textbf{Neural Path Feature.} In the dual view, the computation in a DNN is broken down into paths, which leads to an alternative feature/value decomposition. Each path has a signal at its input node, which is gets transmitted to the output if the path is on (i.e., all the gates in the paths are on). On its way to the output, (if transmitted) the input signal of a path is scaled by a `value' equal the product of the weights in the path. The input and the on/off of the path is encoded in a so called \emph{neural path feature} (NPF $\in \R^{\text{total-paths}}$) and the scaling by the weights is encoded by the \emph{neural path value} (NPV $\in \R^{\text{total-paths}}$). The DNN output for an input $x\in\R^{\din}$ , and parameter $\Theta\in\R^{\dnet}$ is given by:
\begin{align}
\texttt{DNN-OUTPUT(x)=}\ip{\texttt{NPF}_{\Theta}\texttt{(x),NPV}_{\Theta}}
\end{align}

\textbf{Subnetwork Interpretation.} For any given input, the NPF coordinate is zero for all the inactive paths. This provides a subnetwork based interpretation, that is, computation from input to output happens via the `active subnetwork' consisting of active paths.  



As as result, the Gram matrix of the NPFs called the \emph{neural path kernel} (NPK) is equal to the \emph{Hadamard} product of the input Gram matrix and a correlation matrix which measures the overlap between the sub-networks active for the various input pairs. 



\textbf{Self-Explanation.}


For this purpose, the dual view exploits the gating property of ReLU, that is, the \emph{on/off} or \emph{active/inactive} states of the ReLUs. A path starts at an input node, passes through a weight and a ReLU in each layer until it reaches the output node. A path is active all the gates in that path active, and its contribution is equal to the product of the signal at the input node and the weights in the path. In the dual view, it is natural to think that depending on the input, some subset of the paths get activated, and computation from input to output is restricted to the `active' subnetwork consisting of such active paths. Thus, the gates are input dependent and the weights remain the same across inputs. Holwever, weights are triggering the gates in the first place. So, in order to separately the understand of their roles, the gates are also physically separated from the weights in \emph{deep gated network} (DGN) setup, wherein, the input dependent gates are generated in a so called \emph{feature network} (which a DNN with ReLU whose sole  is  generation of the gates) and then gating signals are applied as external masks to a so called \emph{value network} which carries out the input to output computation. Having separated the gates and the weights, the role of gates and active subnetworks was investigated in theory and experiments.

\textbf{Neural Path Kernel (Theory).} A \emph{neural path kernel} (NPK) is defined and is equal to the \emph{Hadamard} product of the input Gram matrix and a correlation matrix which measures the overlap between the sub-networks active for the various input pairs. Prior results  \cite{arora2019exact,cao2019generalization,ntk} have shown the equivalence of an infinite width DNN trained using gradient descent and its corresponding \emph{neural tangent kernel} (NTK) matrix, the Gram matrix of the gradient of the network output with respect to the weights. It was shown that when the gates and weights are separated, with the gates being fixed and only the weights trained, under randomised initialisation, in the limit of infinite width, the NTK becomes equal to (but for a scalar term) the NPK. This equivalence between NTK and NPK analytically characterises the role of the active subnetworks.


\textbf{Gate Learning (Experiments).}  It was shown active subnetworks are learnt during training and it improves test accuracy.  Using the gates from a pre-trained DNN as external masks one can retrain the weights and match the test accuracy of the original pre-trained DNN with ReLU. 
%This implies that most useful input dependent information is in the gates. 
It was shown that if gates from a randomly initialised (instead of pre-trained) DNN are used as external masks, and the weights are trained, the test accuracy drops significantly. 
%This implies that gates are learnt when a DNN with ReLU is trained and such learning improves generalisation.
\end{comment}



%In all results above, the gates were generated by a feature network which was a DNN with ReLUs.  Based on our understanding, we propose to replace the ReLUs with identity activations giving rise to a white box architecture called \texttt{DGN-NO-ACT}. Once the ReLU non-linearity is removed, the other operations such as convolution (which is  linear), pooling and batch norm (bias and scaling) are well understood and interpretable in `image processing' terms. 


%We pursue two goals (i) pedagogical: here the pursuit is not propose new methods to beat the state of the art, but to improve our understanding of basic functional components namely weights, activation, depth, width, convolutions with global pooling  and skip connection (ii) practical: here the pursuit is to build a white box model without significance performance loss with respect to state of the art. The pedagogical goal is to drive home the message that, even though the primal and dual views are mathematically equivalent, when compared to the primal, the dual view is a natural and simple way to interpret and understand the inner workings of DNNs with ReLUs. The pedagogical goal is achieved in the following two steps. 





%In this paper, we carry forward this dismantling, where the gates in a DNN are dismantled layer-by-layer, and finally the gates in a layer are dismantled unit-by-unit. The key simplification is in our main claim that gates are indeed the most fundamental entities in DNNs with ReLUs. We provide theoretical basis for this claim and justify the same in experiments. Based on our theory and experiments, we argue that a DNN with ReLU into three functionalities namely (i) gating (ii) pre-activation generation and (iii) weights. While a standard DNN with ReLU is such that these three functionalities are shared/entangled between its weights and activation,  we propose a novel modification wherein we disentangle the three components. 

% separate the functionalities to dedicated for (i) feature generation (without any hidden units), (ii) gating, and (iii) weights. 

%Due to this separation of functionalities network is entirely interpretable by design. Now, we first summarise the main results in the prior work by \cite{npk} who developed a dual view to understand the role of gates in DNNs with ReLUs, followed by the specific contributions in this paper.





%Our main claim is that gates are indeed the most fundamental entities in such DNNs. We provide theoretical basis for the claim and justify the same in experiments. Based on this claim, we propose a novel modification wherein the deep network has separate components to dedicated specifically to address (i) feature generation (without any hidden units), (ii) gating, and (iii) the weights in a decoupled manner. Due to this decoupled network is entirely interpretable by design. Now, we first summarise the main results in the prior work by \cite{npk} who developed a dual view to understand the role of gates in DNNs with ReLUs, followed by the specific contributions in this paper.




 %Recent past has seen two paradigms namely `explainability' and `interpretabilty' to addres the issue of `black box'-ness. In the  `explaniablity' paradigm, one accepts as a fact that complex machine learning tasks might require complex black box models, however, resorts to \emph{post-hoc} \emph{explaination} of the \emph{decisions} of a DNN by building simpler local models. In the `interpretability' paradigm, one builds entirely interpretable white box models in the first place, thereby eliminating the need for \emph{post-hoc} explanations. 

