\section{Conclusion}
Entanglement of the non-linear and the linear operation in each layer of a DNN makes them uninterpretable. This paper proposed a novel DLGN which disentangled the computations in a DNN with ReLUs into two mathematically interpretable linearities, the `primal' linearity from the input to the pre-activations that trigger the gates, and the `dual' linearity in the path space. DLGN recovers more than $83.5\%$ of performance of state-of-the-art DNNs on CIFAR-10 and CIFAR-100. Based on this success of DLGN, the paper concluded by asking `Is DLGN a universal spectral approximator?'.

%Entanglement of the non-linear and the linear operation in each layer of a DNN makes them uninterpretable. This paper proposed a novel DLGN which disentangled and rearranged the computations in a DNN with ReLUs in an interpretable manner. 
%The DLGN has two mathematically interpretable linearities, the `primal' linearity from the input to the pre-activations that trigger the gates, and the `dual' linearity in the path space which is characterised by the neural path kernel. 
%It was shown that the disentangled and interpretable computations in a DLGN recover more than $83.5\%$ of performance of state-of-the-art DNNs on CIFAR-10 and CIFAR-100. Based on this success of DLGN, the paper concluded by asking `Is DLGN a universal spectral approximator?'.
