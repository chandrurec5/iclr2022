%\begin{comment}
\begin{abstract}
Despite their success deep neural networks (DNNs) are still largely considered as black boxes. The main issue is that the linear and non-linear operations are entangled in every layer, making it hard to interpret the hidden layer outputs. In this paper, we look at DNNs with rectified linear units (ReLUs), and focus on the gating property (`on/off' states) of the ReLUs. We extend the recently developed dual view in which the computation is broken path-wise to show that learning in the gates is more crucial, and learning the weights given the gates is characterised analytically via the so called \emph{neural path kernel} (NPK) which depends on inputs and gates. In this paper, we present novel results to show that convolution with global pooling and skip connection provide rotational invariance and ensemble structure to NPK respectively. To address `black box'-ness, we propose a novel interpretable counterpart of DNNs with ReLUs namely deep linearly gated networks (DLGN): the pre-activations to the gates are generated by a deep linear network, and the gates are then applied as external masks to learn the weights in a different network. The DLGN is not an alternative architecture per se, but a disentanglement and an interpretable re-arrangement of the computations in a DNN with ReLUs. The DLGN disentangles the computations into two  `mathematically' interpretable linearities (i) the `primal' linearity between the input and the pre-activations in the gating network and (ii) the `dual' linearity in the path space in the weights network characterised by the NPK. We compare the performance of DNN, DGN and DLGN on CIFAR-10 and CIFAR-100 to show that, the DLGN recovers more than $83.5\%$ of the performance of state-of-the-art DNNs, i.e., while entanglement in the DNNs enable their improved performance,  the `disentangled and interpretable'  computations in the DLGN can still recover most part of the performance. This brings us to an interesting question: `Is DLGN a universal spectral approximator?'%Finally, we use dual view to show that the degradation in the gates is the reason for degradation in the test performance due to upstream training with random labels (this was an open question in \cite{randlabel}).
%the DLGN counterparts of state of the art DNNs recover more than $83.5\%$ of the performance of the DNNs, which implies that while entanglement in the DNNs enable their improved performance,\
 \end{abstract}
%\end{comment}


\begin{comment}
\begin{abstract}
Despite their success deep neural networks (DNNs) are still largely considered as black boxes. The main issue is that the linear and non-linear operations are entangled in every layer, making it hard to interpret the hidden layer outputs. In this paper, we look at DNNs with rectified linear units (ReLUs), and focus on the gating property (`on/off' states) of the ReLUs. We extend the recently developed dual view in which the computation is broken path-wise to show that learning in the gates is more crucial, and learning the weights given the gates is characterised analytically via the so called \emph{neural path kernel} (NPK) which depends on inputs and gates. In this paper, we first extend the dual view to show that convolution with global pooling and skip connection provide rotational invariance and ensemble structure to NPK respectively. In order to address the issue of `black box'-ness, we propose a novel interpretable counterpart of DNNs with ReLUs namely deep linearly gated networks (DLGN): the pre-activations to the gates are generated by a deep linear network, and the gates are then applied as external masks to learn the weights in a different network. The DLGN disentangles the computations into two  `mathematically' interpretable linearities (i) the `primal' linearity between the input and the pre-activations, and (ii) the `dual' linearity in the path space interpreted via the NPK, and the role of gating is to \emph{lift} the primal to the dual. Our experiments on CIFAR-10 and CIFAR-100 show that the `disentangled and interpretable'  computations in the DLGN can recover more than $83.5\%$ of the performance of the DNNs. 
%the DLGN counterparts of state of the art DNNs recover more than $83.5\%$ of the performance of the DNNs, which implies that while entanglement in the DNNs enable their improved performance,\
 \end{abstract}


\begin{abstract}
We consider DNNs with rectified linear units (ReLUs). We focus on the gates, i.e., `on/off' states of the ReLUs. We build on dual view of \cite{npk} in which the computation is broken path-wise, where each path has both gates and weights. They showed that the input dependent gating patterns act like features, and characterised them analytically via the so called \emph{neural path kernel} (NPK) which depends on number of paths simultaneously `on' for a given input pair. New results in this paper deal with: (i) uncovering structural properties of NPK, (ii) demonstrating `layer-path' duality (iii) resolving an open question on training with random labels and (i) building comptetitve white box models.
%Firstly, we present new results that simplify and improve our understanding of DNNs with ReLUs. For this, we present three new theoretical results, using which we interepret the roles of activations, weights, width, depth, convolutions with global pooling and skip connections. 
Firstly, we show that the NPK has a product structure invariant to layer permutation and only depends on the correlation of the gates. We show that convolution with global pooling and skip connection provide rotational invariance and ensemble structure to NPK respectively. Secondly, we show that once the gates are obtained in a layer-by-layer manner, operations destroying the layer-by-layer structure such as permuting the layers, arbitrarily tiling and rotation of the gates and providing a constant input do not degrade performance, because, in all these operations, the correlation of gates is not lost. Thirdly, we use the dual view to resolve the open question related to degradation of test accuracy due to upstream training with random labels : degradation occurs because random labels affect the gates. Finally, we propose a novel model by modifying  DNNs with ReLUs: pre-activations to the gates are generated without any non-linear activations. Interpreted in the dual view, this novel model is entirely white box. We show white box models obtained by modifying VGG and a ResNet (in the proposed way) achieve greater than $90\%$ and close to $70\%$ on CIFAR-10 and CIFAR-100 respectively.  
%We present an improved and simplified understanding of deep neural network (DNNs) with rectified linear units (ReLUs), and use our understanding to build white box models. We focus on the gates, i.e., `on/off' states of the ReLUs. We build on prior work by \cite{npk} developed a dual view to showed that most information is in the gates, and captured the role of the gates analytically via the so called \emph{neural path kernel} (NPK). 
%In this paper, we show that interpreting via the dual view offers novel, fundamental, surprising and counter-intutive results eventually paving way for building white box models. %We achieve our aim by persuing two goals (i) conceptual: where our key objective is improved understanding and not necessarily to beat state of the art  and (ii) practical: where our key objective is to improve interpretability without significant loss with respect to state of the art. 
%FThe conceptual goal is to drive home the DNNs are interpretable in the dual view. 
%We reach our conceptual goal in two steps. 
%Firstly, we present new theoretical results by refining the prior work on dual view for the fully connected case, and extending it to cover the case of convolutions with global pooling and skip connections. The main highlight is that each layer has a base kernel measuring the correlation of gates, and the NPK is a Hadamard product of these base kernels and the input Gram matrix. We experimentally verify that operations destroying the layer-by-layer structure such as permuting the layers, arbitrarily tiling and rotation of the gates and providing a constant input do not degrade performance, because, in all these operations, the correlation of gates is not lost. We also show that upstream training with random labels degrades the gates and hence test accuracy even after downstream training with true labels (this was an open question). Finally, we propose a novel model by modifying  DNNs with ReLUs: we generate the pre-activation to the gates without any non-linear activations. Interpreted in the dual view, this novel model is entirely white box. We show white box models obtained by modifying VGG and a ResNet (in the proposed way) achieve greater than $90\%$ and close to $70\%$ on CIFAR-10 and CIFAR-100 respectively. %The empirical results here are of two kinds (i) conceptual: the key objective is improved understanding by verifying the theory and not necessarily to beat `state of the art' and (ii) practical: the key objective is to build white box models without significant loss with respect to `state of the art'.
%We present an improved and simplified understanding of  deep neural network (DNNs) with rectified linear units (ReLUs). In particular, we focus on the gating property (i.e., \emph{on/off} state) of ReLU, due to which, for each input there is an \emph{active/on} sub-network comprising of those gates which are \emph{on} and the weights between those gates. Recently, \cite{npk} developed a \emph{dual view} to separate the gates and the weights. They showed that most information is in the gates, and captured the role of the active sub-networks analytically via the so called \emph{neural path kernel} (NPK). In this paper, we simplify the NPK by expressing it explicitly in terms of the \emph{correlation of gates}, and derive the additional properties of NPK in the presence of convolutions and skip connections. The main highlight is that each layer has a base kernel measuring the correlation of gates, and the NPK is a Hadamard product of these base kernels and the input Gram matrix.  These show that the dual view is a natural way to think about the inner workings of DNNs with ReLUs. Finally, we propose a novel deep network (we call this \texttt{DGN-No-ACT}) wherein the gates are generated without any non-linear activations. This makes \texttt{DGN-No-ACT} a completely white box model. We show that \texttt{DGN-No-ACT} based on standard architectures achieve more than $90\%$ and close to $70\%$ on CIFAR-10 and CIFAR-100 respectively.


%Finally, we modify standard architectures (VGG19 and a ResNet) to yield two deep gated networks in which feature extraction is free of activations and is separate from the gates and the weights -- these achieve greater than $90\%$ test accuracy on CIFAR-10. 

%The other two theoretical results extend the dual view to cover the cases of convolutions with pooling and skip connections.
%Our main message is that the gates hold most useful information. 
%We present a simplified and improved understanding of the inner workings of deep neural networks (DNNs) with rectified linear units (ReLUs) by focussing on the gating (i.e., `on/off' states) of the ReLUs. We build on prior work by \cite{npk} which also focussed on the role of gates in DNNs with ReLUs.  Our main claim is that gates are indeed the most fundamental entities in such DNNs that hold most useful information. We provide theoretical basis for the claim and experimental justification. Based on this simplified understanding, we conceptualise a DNN with ReLU to have three functional components (i) gating, (ii) pre-activation generation and (iii) weights.  In a  DNN with ReLU these three functionalities are shared/entangled between its weights and activation. We propose a novel modification to disentangle these three components thereby making the deep network entirely interpretable. We show that applying this modification on standard state of the art DNNs makes them entirely interpretable without significant loss of performance.
%we propose a novel modification that yields an entirely interpretable deep network.
 
%We present an improved and simplified understanding of  deep neural network (DNNs) with rectified linear units (ReLUs) by focussing on the gating property (i.e., on/off state) of ReLU.  We build on the \emph{dual view} introduced by \cite{npk}. The key simplification is the claim that DNNs with ReLUs are characterised by the \emph{correlation of gates}. We verify this claim by showing that operations destroying the layer-by-layer structure such as permuting the layers, arbitrarily tiling and rotation of the gates and providing a constant input do not degrade performance, because, in all these operations, the correlation of gates is not lost. We then take up an open question related to the degradation of test accuracy due to upstream training with random labels for study. Using the dual view, we show that this degradation is attributed to the gates thereby demonstrating the importance of the role of gates and efficacy of the dual view in understanding DNNs with ReLUs. Based on our improved understanding, we propose a novel modification that improves `interpretability' :  here (i) feature extraction, (ii) gating and (iii) weights are decoupled. We show on standard architectures that this novel modification achieves greater than $90\%$ and close to $70\%$ test accuracies on CIFAR-10 and CIFAR-100 respectively while improving interpretability.

%We present an improved and simplified understanding of  deep neural network (DNNs) with rectified linear units (ReLUs). We build upon the dual view developed by \cite{npk}, wherein the computations are broken path-by-path as opposed to the primal view where computations are layer-by-layer. In the dual view, the output is expressed as an inner product of so called \emph{neural path features} (which encodes the input dependent computation) and so called \emph{neural path values} (which encode computations common across inputs). Our theoretical results refine the prior dual view for fully connected case, and extend it to cover the cases of convolutions with global pooling and skip connections. We also present empirical results which, are open and counter intuitive from the primal view, however, are reconciled in the dual view. These results suggest that dual view is the natural way to interpret DNNs with ReLUs. Finally, we propose a novel modified deep network wherein the neural path features are generated without using any non-linear activations (which call this network \texttt{DGN-No-ACT}). Here, features are not hidden, and are entirely interpretable in terms of standard `image processing' operations. This makes \texttt{DGN-No-ACT} a completely white box model. We show that \texttt{DGN-No-ACT} based on standard architectures achieve more than $90\%$ and close to $70\%$ on CIFAR-10 and CIFAR-100 respectively.

%We present an improved and simplified understanding of  deep neural network (DNNs) with rectified linear units (ReLUs) by focussing on the gating (i.e., `active/inactive' states) of the ReLUs. We build upon the dual view wherein the computation in a DNN is broken down into paths. Prior work on dual view (for fully connected case) showed that the most useful information in the gates, and is characterised by a so called \emph{neural path kernel} (NPK) which depends on the total number of active paths. Our theoretical results refine the prior dual view for fully connected case, and extend it to cover the cases of convolutions with global pooling and skip connections. The main highlight is that each layer has a base kernel measuring the correlation of gates, and the NPK is a Hadamard product of these base kernels and the input Gram matrix. To our knowledge, this is the simplest kernel in literature that analytically characterises the gates. We experimentally verify that operations destroying the layer-by-layer structure such as permuting the layers, arbitrarily tiling and rotation of the gates and providing a constant input do not degrade performance, because, in all these operations, the correlation of gates is not lost. We also show experimentally that (open question related to) the degradation in test accuracy due to upstream training with random labels is because of the degradation to gates, thereby reinforcing the importance of gates. %We also present empirical results which, are open and counter intuitive from the primal view, however, are reconciled in the dual view. These results suggest that dual view is the natural way to interpret DNNs with ReLUs. 
%Finally, we propose a novel modified deep network wherein the gates are generated without using any non-linear activations (which call this network \texttt{DGN-No-ACT}). Here, features are not hidden, and are entirely interpretable in terms of standard `image processing' operations. This makes \texttt{DGN-No-ACT} a completely white box model. We show that \texttt{DGN-No-ACT} based on standard architectures achieve more than $90\%$ and close to $70\%$ on CIFAR-10 and CIFAR-100 respectively.
%for a given pair of inputs is equal to the product of the inner product of the inputs and the sizes of the overlapping active sub-networks corresponding to the inputs.
\end{abstract}
\end{comment}






